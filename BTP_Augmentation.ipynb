{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UOQHaFRvJEjJ"
      },
      "outputs": [],
      "source": [
        "!unzip /content/dataset_anemia_preprocessed.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYWQPMg2IHEN"
      },
      "outputs": [],
      "source": [
        "#problems:,preprocessing only 116 italy out of 123 images\n",
        "#NOtes:augmentaion failed on jupyter,using albumnetations,some transparent some white bsckgroung, some no alpha\n",
        "#augentation parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add mask logic,finalize augmentation"
      ],
      "metadata": {
        "id": "RCex5ARqVatC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Augmentation to Only Training Data"
      ],
      "metadata": {
        "id": "F2tqkD48vRiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/BTP 1/dataset anemia.zip\""
      ],
      "metadata": {
        "id": "R5xErafjkgmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "shutil.rmtree(\"/content/augmented_dataset\", ignore_errors=True)\n",
        "print(\"Deleted folder: anemia_augmented\")\n",
        "\n",
        "csv_path=OUTPUT_CSV\n",
        "\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    os.remove(csv_path)\n",
        "    print(\"Deleted:\", csv_path)\n",
        "\n",
        "# if os.path.exists(zip_path):\n",
        "#     os.remove(zip_path)\n",
        "#     print(\"Deleted:\", zip_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "wOfpdMaYna8Y",
        "outputId": "6e4afe13-d40d-4e51-b230-f7a0dfd099cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted folder: anemia_augmented\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'OUTPUT_CSV' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2330998489.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deleted folder: anemia_augmented\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcsv_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OUTPUT_CSV' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Helper Functions"
      ],
      "metadata": {
        "id": "YlZyBZh71Qe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# ðŸ§© Morphological Opening Function  (YOUR EXACT LOGIC)\n",
        "# =======================================================\n",
        "def apply_morph_opening(image_path):\n",
        "    img = load_corrected_image(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    if img.dtype == np.uint16:\n",
        "        img = (img / 256).astype(np.uint8)\n",
        "\n",
        "    # Work in BGR directly\n",
        "    bgr = img.copy()\n",
        "\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    opened_bgr = np.zeros_like(bgr)\n",
        "\n",
        "    for c in range(3):\n",
        "        opened_bgr[:, :, c] = cv2.morphologyEx(bgr[:, :, c], cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "\n",
        "    return opened_bgr   # <--- NOW RETURN BGR\n",
        "\n",
        "\n",
        "\n",
        "def apply_aug_whole_image(image,aug):\n",
        "    # ---- Run aug with mask together (IMPORTANT) ----\n",
        "    aug_out = aug(image=image)\n",
        "\n",
        "    aug_img = aug_out[\"image\"]\n",
        "    # new_mask = aug_out[\"mask\"]\n",
        "\n",
        "    # White-out outside conjunctiva region\n",
        "    # aug_img[new_mask == 0] = 255\n",
        "\n",
        "    return aug_img\n",
        "\n",
        "\n",
        "from PIL import Image, ImageOps, UnidentifiedImageError\n",
        "\n",
        "def load_corrected_image(path):\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        img = ImageOps.exif_transpose(img)  # auto-fix EXIF rotation\n",
        "        img = np.array(img)                # -> numpy RGB\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        return img\n",
        "    except (UnidentifiedImageError, OSError, ValueError):\n",
        "        print(f\"[CORRUPT] Skipping file: {path}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "ILoj45DFW1bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MAML Setup"
      ],
      "metadata": {
        "id": "lpUoAXFpzcp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. SINGLE DICTIONARY OF ALL ATOMIC AUGMENTATIONS\n",
        "# --------------------------------------------------\n",
        "AUG = {\n",
        "    \"affine\": A.Affine(\n",
        "        scale=(0.85, 1.15),\n",
        "        rotate=(-12, 12),\n",
        "        shear=(-4, 4),\n",
        "        p=1.0\n",
        "    ),\n",
        "\n",
        "    \"color\": A.ColorJitter(\n",
        "        brightness=0.20,\n",
        "        contrast=0.20,\n",
        "        saturation=0.12,\n",
        "        hue=0.02,\n",
        "        p=1.0\n",
        "    ),\n",
        "\n",
        "    \"gauss_noise\": A.GaussNoise(\n",
        "        std_range=(0.15, 0.25),\n",
        "        p=1.0\n",
        "    ),\n",
        "\n",
        "    \"iso_noise\": A.ISONoise(\n",
        "        intensity=(0.25, 0.50),\n",
        "        color_shift=(0.02, 0.07),\n",
        "        p=1.0\n",
        "    ),\n",
        "\n",
        "    \"motion_blur\": A.MotionBlur(\n",
        "        blur_limit=(5, 15),\n",
        "        p=1.0\n",
        "    ),\n",
        "\n",
        "    \"gaussian_blur\": A.GaussianBlur(\n",
        "        blur_limit=(5, 9),\n",
        "        p=1.0\n",
        "    ),\n",
        "\n",
        "    \"downscale\": A.Downscale(\n",
        "        scale_range=(0.60, 0.85),\n",
        "        p=1.0\n",
        "    ),\n",
        "\n",
        "    \"compression\": A.ImageCompression(\n",
        "        quality_range=(60, 85),\n",
        "        p=1.0\n",
        "    ),\n",
        "}\n",
        "PIPE = {\n",
        "    # -----------------------\n",
        "    # 1â€“7: Single Augmentations\n",
        "    # -----------------------\n",
        "    \"Aug1\":  [\"affine\"],\n",
        "    \"Aug2\":  [\"color\"],\n",
        "    \"Aug3\":  [\"gauss_noise\"],\n",
        "    \"Aug4\":  [\"iso_noise\"],\n",
        "    \"Aug5\":  [\"motion_blur\"],\n",
        "    \"Aug6\":  [\"gaussian_blur\"],\n",
        "    \"Aug7\":  [\"downscale\",\"compression\"],\n",
        "\n",
        "    # -----------------------\n",
        "    # 8â€“13: Combined Augmentations\n",
        "    # -----------------------\n",
        "    \"Aug8\":   [\"color\", \"motion_blur\"],\n",
        "    \"Aug9\":   [\"affine\", \"color\"],\n",
        "    \"Aug10\":  [\"affine\", \"gaussian_blur\"],\n",
        "    \"Aug11\":  [\"color\", \"gauss_noise\"],\n",
        "    \"Aug12\":  [\"gaussian_blur\", \"gauss_noise\"],\n",
        "    \"Aug13\":  [\"iso_noise\", \"compression\"],\n",
        "}\n",
        "\n",
        "def get_pipeline(name):\n",
        "    return A.Compose([AUG[a] for a in PIPE[name]])\n",
        "\n",
        "def MAML_process_split(df_split, mode=\"train\"):\n",
        "    \"\"\"\n",
        "    df_split : DataFrame (train or valid)\n",
        "    mode : \"train\" or \"valid\"\n",
        "    \"\"\"\n",
        "    assert mode in [\"train\", \"valid\"]\n",
        "\n",
        "    # Output folder\n",
        "    OUT_DIR = os.path.join(OUTPUT_IMG_DIR, mode)\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for _, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"Processing {mode}\"):\n",
        "        region = row[\"Region\"]\n",
        "        pid = str(int(row[\"Number\"]))\n",
        "        age = row[\"Age\"]\n",
        "        gender = row[\"Gender\"]\n",
        "        hgb = row[\"Hgb\"]\n",
        "\n",
        "        # Patient directory\n",
        "        patient_dir = os.path.join(ROOT_DIR, region, pid)\n",
        "\n",
        "        # Find conjunctiva image\n",
        "        orig_file = None\n",
        "        for f in os.listdir(patient_dir):\n",
        "            if \"forniceal_palpebral\" in f.lower() and f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "                orig_file = f\n",
        "                break\n",
        "\n",
        "        if orig_file is None:\n",
        "            print(f\"[WARNING] No image found in {patient_dir}\")\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(patient_dir, orig_file)\n",
        "\n",
        "        # Morph preprocessing\n",
        "        processed, mask = apply_morph_opening(img_path)\n",
        "        if processed is None:\n",
        "            continue\n",
        "\n",
        "        # Create output directory\n",
        "        out_dir = os.path.join(OUT_DIR, region, pid)\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "        # Save processed original\n",
        "        orig_save_path = os.path.join(out_dir, \"original.png\")\n",
        "        cv2.imwrite(orig_save_path, processed)\n",
        "\n",
        "        # Add original to CSV\n",
        "        records.append([orig_save_path, age, gender, hgb, region])\n",
        "\n",
        "        # -------------------------\n",
        "        # ðŸŒŸ TRAIN AUGMENTATION ONLY\n",
        "        # -------------------------\n",
        "        if mode == \"train\":\n",
        "            img_rgb = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            for k in range(N_AUGS):\n",
        "                aug = get_pipeline(f\"Aug{k+1}\")\n",
        "                aug_img = apply_aug_inside_mask(img_rgb, aug, mask)\n",
        "                aug_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "                aug_name = f\"aug_{k}.png\"\n",
        "                aug_path = os.path.join(out_dir, aug_name)\n",
        "\n",
        "                cv2.imwrite(aug_path, aug_bgr)\n",
        "\n",
        "                records.append([aug_path, age, gender, hgb, region])\n",
        "\n",
        "    # -----------------------\n",
        "    # Create final DataFrame\n",
        "    # -----------------------\n",
        "    out_df = pd.DataFrame(records, columns=[\"image_path\", \"Age\", \"Gender\", \"Hgb\", \"Region\"])\n",
        "\n",
        "    # Encoding\n",
        "    out_df[\"Gender\"] = out_df[\"Gender\"].map({\"M\": 1, \"F\": 0}).astype(float)\n",
        "    out_df[\"Region\"] = out_df[\"Region\"].map({\"India\": 0, \"Italy\": 1}).astype(float)\n",
        "\n",
        "    # Clean Hgb\n",
        "    out_df[\"Hgb\"] = pd.to_numeric(out_df[\"Hgb\"], errors=\"coerce\")\n",
        "    out_df = out_df.dropna(subset=[\"Hgb\"])\n",
        "\n",
        "    # Normalize Age (Age/100)\n",
        "    out_df[\"Age\"] = out_df[\"Age\"] / 100.0\n",
        "\n",
        "    return out_df\n"
      ],
      "metadata": {
        "id": "UEItpTrguZgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BPA_Net Setup"
      ],
      "metadata": {
        "id": "NJkEBFy2zlkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "\n",
        "# ----------------------------------------\n",
        "# BEST 5 AUGMENTATIONS WITH PROBABILITIES\n",
        "# ----------------------------------------\n",
        "AUG_PIPELINE = A.Compose([\n",
        "    A.Affine(\n",
        "        scale=(0.85, 1.15),\n",
        "        rotate=(-12, 12),\n",
        "        shear=(-4, 4),\n",
        "        p=0.35\n",
        "    ),\n",
        "\n",
        "    A.ColorJitter(\n",
        "        brightness=0.20,\n",
        "        contrast=0.20,\n",
        "        saturation=0.12,\n",
        "        hue=0.02,\n",
        "        p=0.25\n",
        "    ),\n",
        "\n",
        "    A.GaussNoise(\n",
        "        std_range=(0.15, 0.25),\n",
        "        p=0.30\n",
        "    ),\n",
        "\n",
        "    A.GaussianBlur(\n",
        "        blur_limit=(5, 9),\n",
        "        p=0.25\n",
        "    ),\n",
        "\n",
        "    A.ImageCompression(\n",
        "            quality_range=(60, 85),\n",
        "            p=0.40\n",
        ")\n",
        "])\n",
        "\n",
        "def BPANet_process_split(df_split, mode=\"train\"):\n",
        "    \"\"\"\n",
        "    df_split : DataFrame (train or valid)\n",
        "    mode : \"train\" or \"valid\"\n",
        "    \"\"\"\n",
        "    assert mode in [\"train\", \"valid\"]\n",
        "\n",
        "    OUT_DIR = os.path.join(OUTPUT_IMG_DIR, mode)\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "    records = []\n",
        "\n",
        "    for _, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"Processing {mode}\"):\n",
        "        region = row[\"Region\"]\n",
        "        pid = str(int(row[\"Number\"]))\n",
        "        age = row[\"Age\"]\n",
        "        gender = row[\"Gender\"]\n",
        "        hgb = row[\"Hgb\"]\n",
        "\n",
        "        patient_dir = os.path.join(ROOT_DIR, region, pid)\n",
        "\n",
        "        orig_file = None\n",
        "        for f in os.listdir(patient_dir):\n",
        "            if (\"forniceal\" not in f.lower()) and (\"palpebral\" not in f.lower()) and f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "                orig_file = f\n",
        "                break\n",
        "\n",
        "        if orig_file is None:\n",
        "            print(f\"[WARNING] No image found in {patient_dir}\")\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(patient_dir, orig_file)\n",
        "\n",
        "        # Only morph opening now (mask removed)\n",
        "        processed = apply_morph_opening(img_path)\n",
        "        if processed is None:\n",
        "            continue\n",
        "\n",
        "        out_dir = os.path.join(OUT_DIR, region, pid)\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "        # ------------------------------\n",
        "        # VALID â†’ save original only\n",
        "        # ------------------------------\n",
        "        if mode == \"valid\":\n",
        "            save_path = os.path.join(out_dir, \"original.png\")\n",
        "            cv2.imwrite(save_path, processed)\n",
        "\n",
        "            records.append([save_path, age, gender, hgb, region])\n",
        "\n",
        "        else:  # ------------------- TRAIN AUG -------------------\n",
        "            img_rgb = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            aug_img = apply_aug_whole_image(img_rgb, AUG_PIPELINE)\n",
        "            aug_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            aug_path = os.path.join(out_dir, f\"aug_{pid}.png\")\n",
        "            cv2.imwrite(aug_path, aug_bgr)\n",
        "\n",
        "            records.append([aug_path, age, gender, hgb, region])\n",
        "\n",
        "    # --------------------\n",
        "    # Build output dataframe\n",
        "    # --------------------\n",
        "    out_df = pd.DataFrame(records, columns=[\"image_path\", \"Age\", \"Gender\", \"Hgb\", \"Region\"])\n",
        "\n",
        "    out_df[\"Gender\"] = out_df[\"Gender\"].map({\"M\": 1, \"F\": 0}).astype(float)\n",
        "    out_df[\"Region\"] = out_df[\"Region\"].map({\"India\": 0, \"Italy\": 1}).astype(float)\n",
        "\n",
        "    out_df[\"Hgb\"] = pd.to_numeric(out_df[\"Hgb\"], errors=\"coerce\")\n",
        "    out_df = out_df.dropna(subset=[\"Hgb\"])\n",
        "\n",
        "    out_df[\"Age\"] = out_df[\"Age\"] / 100.0\n",
        "\n",
        "    return out_df"
      ],
      "metadata": {
        "id": "FUKqWm0Iw9GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Augmentation based on setup"
      ],
      "metadata": {
        "id": "OjDK80oU1H-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Split BEFORE augmentation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# =======================================================\n",
        "# ðŸ”§ CONFIG\n",
        "# =======================================================\n",
        "ROOT_DIR = \"/content/dataset anemia\"\n",
        "INDIA_XLSX = os.path.join(ROOT_DIR, \"India\", \"India.xlsx\")\n",
        "ITALY_XLSX = os.path.join(ROOT_DIR, \"Italy\", \"Italy.xlsx\")\n",
        "\n",
        "OUTPUT_IMG_DIR = \"/content/augmented_dataset\"\n",
        "os.makedirs(OUTPUT_IMG_DIR, exist_ok=True)\n",
        "\n",
        "N_AUGS = 13\n",
        "\n",
        "# =======================================================\n",
        "# LOAD METADATA\n",
        "# =======================================================\n",
        "df_india = pd.read_excel(INDIA_XLSX)\n",
        "df_india[\"Region\"] = \"India\"\n",
        "\n",
        "df_italy = pd.read_excel(ITALY_XLSX)\n",
        "df_italy[\"Region\"] = \"Italy\"\n",
        "\n",
        "df = pd.concat([df_india, df_italy], ignore_index=True)\n",
        "\n",
        "df_train, df_val = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=df[\"Region\"]\n",
        ")\n",
        "\n",
        "train_df = BPANet_process_split(df_train, mode=\"valid\")\n",
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "\n",
        "valid_df = BPANet_process_split(df_val, mode=\"valid\")\n",
        "valid_df.to_csv(\"valid.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "dsE_Mnq10yxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932a6b75-3618-48b0-950d-7327581b1ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing valid:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 136/174 [02:10<00:33,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CORRUPT] Skipping file: /content/dataset anemia/Italy/95/T_64_20190612_092742_palplebral.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [02:46<00:00,  1.04it/s]\n",
            "Processing valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:41<00:00,  1.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Augmented Data & CSV"
      ],
      "metadata": {
        "id": "G-vSSn-B1lDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "def download_outputs(folder_path, csv_path_1, csv_path_2):\n",
        "\n",
        "    # 1. ZIP + DOWNLOAD FOLDER\n",
        "    if os.path.exists(folder_path):\n",
        "        zip_name = \"augmented_dataset\"\n",
        "        shutil.make_archive(zip_name, \"zip\", folder_path)\n",
        "        print(f\"Zipped folder: {zip_name}.zip\")\n",
        "        files.download(f\"{zip_name}.zip\")\n",
        "    else:\n",
        "        print(f\"âŒ Folder not found: {folder_path}\")\n",
        "\n",
        "    # 2. DOWNLOAD CSV 1\n",
        "    if os.path.exists(csv_path_1):\n",
        "        print(f\"CSV found â†’ downloading: {csv_path_1}\")\n",
        "        files.download(csv_path_1)\n",
        "    else:\n",
        "        print(f\"âš ï¸ CSV not found at: {csv_path_1}\")\n",
        "\n",
        "    # 3. DOWNLOAD CSV 2\n",
        "    if os.path.exists(csv_path_2):\n",
        "        print(f\"CSV found â†’ downloading: {csv_path_2}\")\n",
        "        files.download(csv_path_2)\n",
        "    else:\n",
        "        print(f\"âš ï¸ CSV not found at: {csv_path_2}\")\n",
        "\n",
        "\n",
        "# âœ… Correct call\n",
        "download_outputs(\n",
        "    folder_path=\"/content/augmented_dataset\",\n",
        "    csv_path_1=\"/content/train.csv\",\n",
        "    csv_path_2=\"/content/valid.csv\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ALqaTnno1kN5",
        "outputId": "0e708a70-a968-4a62-c555-b7511378543a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped folder: augmented_dataset.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_94408963-92fe-48a8-b37d-e625b7ad30ba\", \"augmented_dataset.zip\", 1417508538)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV found â†’ downloading: /content/train.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_20450fc7-6a4f-4794-bc60-0475ea66f3d1\", \"train.csv\", 11595)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV found â†’ downloading: /content/valid.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_86fa4c8b-e4df-459c-abc5-69f5f0f25e06\", \"valid.csv\", 3097)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5NCLQrXR23Yx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "F2tqkD48vRiO",
        "lpUoAXFpzcp9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}